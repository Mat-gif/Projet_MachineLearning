{"cells":[{"cell_type":"markdown","source":["-> Chargement des librairies et fonctions\n","\n","// Ici je retest tout avec les 10 topic majoritaire par et le titre"],"metadata":{"collapsed":false,"id":"w3sxIvg3_McQ"}},{"cell_type":"code","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/projet_ML/Projet_MachineLearning\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["false      210\n","true       210\n","mixture    210\n","other      210\n","Name: our rating, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-d18f5beeeaa5>:238: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n","  data_brute.title_text = data_brute.title + data_brute.text\n"]},{"output_type":"stream","name":"stdout","text":["Extraction des meilleurs param√®tres pour le corpus via BOW : \n","topics: 10  alpha: 0.500  eta: 0.500  coherence: 0.302\n","topics: 10  alpha: 0.500  eta: 1.000  coherence: 0.367\n","topics: 10  alpha: 0.500  eta: 1.500  coherence: 0.341\n","topics: 10  alpha: 1.000  eta: 0.500  coherence: 0.345\n","topics: 10  alpha: 1.000  eta: 1.000  coherence: 0.417\n","topics: 10  alpha: 1.000  eta: 1.500  coherence: 0.365\n","topics: 10  alpha: 1.500  eta: 0.500  coherence: 0.348\n","topics: 10  alpha: 1.500  eta: 1.000  coherence: 0.366\n","topics: 10  alpha: 1.500  eta: 1.500  coherence: 0.470\n","topics: 12  alpha: 0.500  eta: 0.500  coherence: 0.369\n","topics: 12  alpha: 0.500  eta: 1.000  coherence: 0.387\n","topics: 12  alpha: 0.500  eta: 1.500  coherence: 0.367\n","topics: 12  alpha: 1.000  eta: 0.500  coherence: 0.404\n","topics: 12  alpha: 1.000  eta: 1.000  coherence: 0.365\n","topics: 12  alpha: 1.000  eta: 1.500  coherence: 0.279\n","topics: 12  alpha: 1.500  eta: 0.500  coherence: 0.346\n","topics: 12  alpha: 1.500  eta: 1.000  coherence: 0.451\n","topics: 12  alpha: 1.500  eta: 1.500  coherence: 0.365\n","topics: 14  alpha: 0.500  eta: 0.500  coherence: 0.321\n","topics: 14  alpha: 0.500  eta: 1.000  coherence: 0.389\n","topics: 14  alpha: 0.500  eta: 1.500  coherence: 0.411\n","topics: 14  alpha: 1.000  eta: 0.500  coherence: 0.380\n","topics: 14  alpha: 1.000  eta: 1.000  coherence: 0.345\n","topics: 14  alpha: 1.000  eta: 1.500  coherence: 0.513\n","topics: 14  alpha: 1.500  eta: 0.500  coherence: 0.330\n","topics: 14  alpha: 1.500  eta: 1.000  coherence: 0.413\n","topics: 14  alpha: 1.500  eta: 1.500  coherence: 0.373\n","topics: 16  alpha: 0.500  eta: 0.500  coherence: 0.350\n","topics: 16  alpha: 0.500  eta: 1.000  coherence: 0.369\n","topics: 16  alpha: 0.500  eta: 1.500  coherence: 0.495\n","topics: 16  alpha: 1.000  eta: 0.500  coherence: 0.364\n","topics: 16  alpha: 1.000  eta: 1.000  coherence: 0.388\n","topics: 16  alpha: 1.000  eta: 1.500  coherence: 0.477\n","topics: 16  alpha: 1.500  eta: 0.500  coherence: 0.371\n","topics: 16  alpha: 1.500  eta: 1.000  coherence: 0.486\n","topics: 16  alpha: 1.500  eta: 1.500  coherence: 0.516\n","topics: 18  alpha: 0.500  eta: 0.500  coherence: 0.324\n","topics: 18  alpha: 0.500  eta: 1.000  coherence: 0.385\n","topics: 18  alpha: 0.500  eta: 1.500  coherence: 0.469\n","topics: 18  alpha: 1.000  eta: 0.500  coherence: 0.372\n","topics: 18  alpha: 1.000  eta: 1.000  coherence: 0.422\n","topics: 18  alpha: 1.000  eta: 1.500  coherence: 0.492\n","topics: 18  alpha: 1.500  eta: 0.500  coherence: 0.411\n","topics: 18  alpha: 1.500  eta: 1.000  coherence: 0.385\n","topics: 18  alpha: 1.500  eta: 1.500  coherence: 0.421\n"]},{"output_type":"display_data","data":{"text/plain":["    topics  alpha  eta  coherence\n","0       16    1.5  1.5   0.515825\n","1       14    1.0  1.5   0.512542\n","2       16    0.5  1.5   0.494890\n","3       18    1.0  1.5   0.492084\n","4       16    1.5  1.0   0.486113\n","5       16    1.0  1.5   0.476774\n","6       10    1.5  1.5   0.470384\n","7       18    0.5  1.5   0.469245\n","8       12    1.5  1.0   0.451040\n","9       18    1.0  1.0   0.422019\n","10      18    1.5  1.5   0.421130\n","11      10    1.0  1.0   0.417132\n","12      14    1.5  1.0   0.413005\n","13      14    0.5  1.5   0.410741\n","14      18    1.5  0.5   0.410610\n","15      12    1.0  0.5   0.403747\n","16      14    0.5  1.0   0.389068\n","17      16    1.0  1.0   0.387848\n","18      12    0.5  1.0   0.387327\n","19      18    0.5  1.0   0.385467\n","20      18    1.5  1.0   0.385303\n","21      14    1.0  0.5   0.379524\n","22      14    1.5  1.5   0.373027\n","23      18    1.0  0.5   0.371602\n","24      16    1.5  0.5   0.371286\n","25      12    0.5  0.5   0.369080\n","26      16    0.5  1.0   0.368887\n","27      12    0.5  1.5   0.367438\n","28      10    0.5  1.0   0.367285\n","29      10    1.5  1.0   0.366428\n","30      12    1.0  1.0   0.365474\n","31      10    1.0  1.5   0.365185\n","32      12    1.5  1.5   0.364671\n","33      16    1.0  0.5   0.363775\n","34      16    0.5  0.5   0.350479\n","35      10    1.5  0.5   0.348224\n","36      12    1.5  0.5   0.346026\n","37      10    1.0  0.5   0.345331\n","38      14    1.0  1.0   0.344883\n","39      10    0.5  1.5   0.340579\n","40      14    1.5  0.5   0.329811\n","41      18    0.5  0.5   0.324420\n","42      14    0.5  0.5   0.320725\n","43      10    0.5  0.5   0.301995\n","44      12    1.0  1.5   0.278821"],"text/html":["\n","  <div id=\"df-ddc3382a-3174-4a7b-b4e9-bcb5da94ee5a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topics</th>\n","      <th>alpha</th>\n","      <th>eta</th>\n","      <th>coherence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>16</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>0.515825</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>14</td>\n","      <td>1.0</td>\n","      <td>1.5</td>\n","      <td>0.512542</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>16</td>\n","      <td>0.5</td>\n","      <td>1.5</td>\n","      <td>0.494890</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>18</td>\n","      <td>1.0</td>\n","      <td>1.5</td>\n","      <td>0.492084</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>16</td>\n","      <td>1.5</td>\n","      <td>1.0</td>\n","      <td>0.486113</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>16</td>\n","      <td>1.0</td>\n","      <td>1.5</td>\n","      <td>0.476774</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>10</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>0.470384</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>18</td>\n","      <td>0.5</td>\n","      <td>1.5</td>\n","      <td>0.469245</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>12</td>\n","      <td>1.5</td>\n","      <td>1.0</td>\n","      <td>0.451040</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>18</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.422019</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>18</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>0.421130</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>10</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.417132</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>14</td>\n","      <td>1.5</td>\n","      <td>1.0</td>\n","      <td>0.413005</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>14</td>\n","      <td>0.5</td>\n","      <td>1.5</td>\n","      <td>0.410741</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>18</td>\n","      <td>1.5</td>\n","      <td>0.5</td>\n","      <td>0.410610</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>12</td>\n","      <td>1.0</td>\n","      <td>0.5</td>\n","      <td>0.403747</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>14</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>0.389068</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>16</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.387848</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>12</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>0.387327</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>18</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>0.385467</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>18</td>\n","      <td>1.5</td>\n","      <td>1.0</td>\n","      <td>0.385303</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>14</td>\n","      <td>1.0</td>\n","      <td>0.5</td>\n","      <td>0.379524</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>14</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>0.373027</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>18</td>\n","      <td>1.0</td>\n","      <td>0.5</td>\n","      <td>0.371602</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>16</td>\n","      <td>1.5</td>\n","      <td>0.5</td>\n","      <td>0.371286</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>12</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>0.369080</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>16</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>0.368887</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>12</td>\n","      <td>0.5</td>\n","      <td>1.5</td>\n","      <td>0.367438</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>10</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>0.367285</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>10</td>\n","      <td>1.5</td>\n","      <td>1.0</td>\n","      <td>0.366428</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>12</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.365474</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>10</td>\n","      <td>1.0</td>\n","      <td>1.5</td>\n","      <td>0.365185</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>12</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>0.364671</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>16</td>\n","      <td>1.0</td>\n","      <td>0.5</td>\n","      <td>0.363775</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>16</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>0.350479</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>10</td>\n","      <td>1.5</td>\n","      <td>0.5</td>\n","      <td>0.348224</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>12</td>\n","      <td>1.5</td>\n","      <td>0.5</td>\n","      <td>0.346026</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>10</td>\n","      <td>1.0</td>\n","      <td>0.5</td>\n","      <td>0.345331</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>14</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.344883</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>10</td>\n","      <td>0.5</td>\n","      <td>1.5</td>\n","      <td>0.340579</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>14</td>\n","      <td>1.5</td>\n","      <td>0.5</td>\n","      <td>0.329811</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>18</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>0.324420</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>14</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>0.320725</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>10</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>0.301995</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>12</td>\n","      <td>1.0</td>\n","      <td>1.5</td>\n","      <td>0.278821</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddc3382a-3174-4a7b-b4e9-bcb5da94ee5a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ddc3382a-3174-4a7b-b4e9-bcb5da94ee5a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ddc3382a-3174-4a7b-b4e9-bcb5da94ee5a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["import sys\n","from google.colab import drive\n","drive.mount('/content/drive')\n","my_local_drive = \"/content/drive/MyDrive/projet_ML/Projet_MachineLearning\"\n","# fonctions utilities (affichage, confusion, etc.)\n","sys.path.append(my_local_drive)\n","# Se positionner sur le r√©pertoire associ√©\n","%cd $my_local_drive\n","%pwd\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","\n","# fonctions utilities (affichage, confusion, etc.)\n","from Fonction.MyNLPUtilities import *\n","# fonctions utilities (fonction de clean, import etc etc)\n","from Fonction.myFonction import *\n","\n","from Fonction.AllModels import *\n","# librairies de gensim\n","import gensim\n","from gensim.utils import simple_preprocess\n","from gensim.models import CoherenceModel\n","from gensim.models import Phrases\n","from gensim.models.phrases import Phraser\n","from gensim import corpora\n","from gensim import models\n","\n","import re\n","import spacy\n","import gensim\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.corpus import wordnet\n","import gensim\n","from gensim.utils import simple_preprocess\n","from gensim.models import Phrases\n","from gensim.models.phrases import Phraser\n","from gensim import corpora\n","from gensim import models\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","\n","stop_words = set(stopwords.words('english'))\n","\n","nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n","#nlp = spacy.load('en', disable=['parser', 'ner'])\n","\n","\n","data_brute = pd.read_csv('./Data_equilibre/MyData_Sprint1et2.csv', sep=\",\")\n","# data_brute = data_brute.drop_duplicates()\n","print(data_brute['our rating'].value_counts())\n","\n","\n","def MyCleanTextsforLDA(texts,\n","                       min_count=1, # nombre d'apparitions minimale pour un bigram\n","                       threshold=2,\n","                       no_below=1, # nombre minimum d'apparitions pour √™tre dans le dictionnaire\n","                       no_above=0.5, # pourcentage maximal (sur la taille totale du corpus) pour filtrer\n","                       stop_words=stop_words\n","                       ):\n","\n","    allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\n","    sentences=texts.copy()\n","\n","    # suppression des caract√®res sp√©ciaux\n","    sentences = [re.sub(r'[^\\w\\s]', ' ', str(sentence)) for sentence in sentences]\n","    # suppression de tous les caract√®res uniques\n","    sentences = [re.sub(r'\\s+[a-zA-Z]\\s+', ' ', str(sentence)) for sentence in sentences]\n","    # substitution des espaces multiples par un seul espace\n","    sentences = [re.sub(r'\\s+', ' ', str(sentence), flags=re.I) for sentence in sentences]\n","\n","    # conversion en minuscule et split des mots dans les textes\n","    sentences = [sentence.lower().split() for sentence in sentences]\n","\n","    # utilisation de spacy pour ne retenir que les allowed_postags\n","    texts_out = []\n","    for sent in sentences:\n","        if len(sent) < (nlp.max_length): # si le texte est trop grand\n","            doc = nlp(\" \".join(sent))\n","            texts_out.append(\" \".join([token.lemma_ for token in doc if token.pos_ in allowed_postags]))\n","        else:\n","            texts_out.append(sent)\n","    sentences=texts_out\n","\n","    # suppression des stopwords\n","    words =[[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in sentences]\n","\n","\n","    # recherche des bigrammes\n","    bigram = Phrases(words, min_count, threshold,delimiter=' ')\n","    bigram_phraser = Phraser(bigram)\n","\n","\n","    # sauvergarde des tokens et des bigrammes\n","    bigram_token = []\n","    for sent in words:\n","        bigram_token.append(bigram_phraser[sent])\n","\n","\n","    # creation du vocabulaire\n","    dictionary = gensim.corpora.Dictionary(bigram_token)\n","\n","\n","    # il est possible de filtrer des mots en fonction de leur occurrence d'apparitions\n","    #dictionary.filter_extremes(no_below, no_above)\n","    # et de compacter le dictionnaire\n","    # dictionary.compactify()\n","    corpus = [dictionary.doc2bow(text) for text in bigram_token]\n","\n","    # recuperaction du tfidf plut√¥t que uniquement le bag of words\n","    tfidf = models.TfidfModel(corpus)\n","    corpus_tfidf = tfidf[corpus]\n","\n","    return corpus, corpus_tfidf, dictionary, bigram_token\n","\n","\n","\n","def get_best_coherence_values(corpus, dictionary, listtokens, start=5, stop=15, step=2):\n","    coherence_values = []\n","    model_list = []\n","    for num_topics in range(start, stop, step):\n","        lda_model = gensim.models.LdaMulticore(corpus=corpus,\n","                                               id2word=dictionary,\n","                                               num_topics=num_topics,\n","                                               random_state=100,\n","                                               chunksize=100,\n","                                               passes=10,\n","                                               workers=20,###\n","                                               eval_every=1,###\n","                                               alpha=0.01, ###\n","                                               eta=0.01,##\n","                                               per_word_topics=True)\n","\n","        coherence_model_lda = CoherenceModel(model=lda_model, texts=listtokens, dictionary=dictionary, coherence='c_v')\n","        model_list.append(lda_model)\n","        coherence_values.append(coherence_model_lda.get_coherence())\n","    return model_list, coherence_values\n","\n","\n","\n","\n","\n","\n","\n","def format_topics_sentences(ldamodel, corpus, texts):\n","    # Initialisation du dataframe de sortie\n","    sent_topics_df = pd.DataFrame()\n","\n","    # Recherche le topic dominant pour chaque document\n","    for i, row_list in enumerate(ldamodel[corpus]):\n","        row = row_list[0] if ldamodel.per_word_topics else row_list\n","\n","        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n","        # Donne le topic dominant, le pourcentage de contribution\n","        # et les mots cl√©s pour chaque document\n","        for j, (topic_num, prop_topic) in enumerate(row):\n","            if j == 0:  # => topic dominant\n","                wp = ldamodel.show_topic(topic_num)\n","                topic_keywords = \", \".join([word for word, prop in wp])\n","                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n","            else:\n","                break\n","    sent_topics_df.columns = ['topic_dominant', 'pourcentage_contrib', 'topic_keywords']\n","\n","    # Ajout du texte original √† la fin de la sortie\n","    contents = pd.Series(texts)\n","    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n","    return(sent_topics_df)\n","\n","\n","stop = stopwords.words('english')\n","\n","\n","# enrichissement des stopwords \n","stop.extend(['always','try','go','get','say','make','would','really',\n","                  'like','came','got'])\n","\n","\n","\n","\n","\n","# ce code est inspir√© de \n","# https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n","def compute_coherence_values(corpus, dictionary, listtokens, k, alpha, eta):\n","    \n","    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n","                                           id2word=dictionary,\n","                                           num_topics=k, \n","                                           random_state=100,\n","                                           chunksize=100,\n","                                           passes=10,\n","                                           alpha=alpha,\n","                                           eta=eta,\n","                                           workers=7,###\n","                                           eval_every=1,###\n","                                           per_word_topics=True)\n","    \n","    coherence_model_lda = CoherenceModel(model=lda_model, texts=listtokens, dictionary=dictionary, coherence='c_v')\n","    \n","    return coherence_model_lda.get_coherence()\n","\n","def MyGridSearchLda (corpus,listtokens,dictionnary,nb_topics,alpha,beta,verbose=1):\n","        \n","    grid = {}\n","    model_results = {'topics': [],\n","                     'alpha': [],\n","                     'eta': [],\n","                     'coherence': []\n","                    }\n","    # iteration sur le nombre de topics\n","    for k in nb_topics:\n","        # iteration sur les valeurs d'alpha\n","        for a in alpha:\n","            # iteration sur les valeurs de eta\n","            for e in eta:\n","                # calcul du score de coherence\n","                cv = compute_coherence_values(corpus=corpus, \n","                                              dictionary=dictionary,\n","                                              listtokens=listtokens,\n","                                              k=k, alpha=a, eta=e)\n","                if verbose==1:\n","                    print ('topics:', k, ' alpha: %0.3f  eta: %0.3f  coherence: %0.3f'%(a,e,cv))\n","                        \n","                # sauvegarde des r√©sultats\n","                model_results['topics'].append(k)\n","                model_results['alpha'].append(a)\n","                model_results['eta'].append(e)\n","                model_results['coherence'].append(cv)\n","                  \n","    df_result=pd.DataFrame(model_results)\n","    df_result = df_result.sort_values('coherence',ascending=False)\n","    df_result.reset_index(drop=True, inplace=True)\n","    return df_result\n","\n","\n","data_brute.title_text = data_brute.title + data_brute.text\n","\n","\n","corpus, corpus_tfidf, dictionary, bigram_token=MyCleanTextsforLDA(data_brute.title_text,stop_words=stop_words)\n","# variation du nombre de topics\n","min_topics = 10\n","max_topics = 20\n","step_size = 2\n","nb_topics = range(min_topics, max_topics, step_size)\n","# variation d'alpha\n","alpha = list(np.arange(0.5, 2, 0.5))\n","# variation de eta\n","eta = list(np.arange(0.5, 2, 0.5))\n","print (\"Extraction des meilleurs param√®tres pour le corpus via BOW : \")\n","df_result=MyGridSearchLda (corpus,bigram_token,dictionary,nb_topics,alpha,eta,verbose=1)  \n","display (df_result)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# corpus_all, corpus_tfidf_all, dictionary_all, bigram_token_all=MyCleanTextsforLDA(data_brute.text,stop_words=stop)\n","\n","\n","# model_list, coherence_values = get_best_coherence_values(dictionary=dictionary_all,\n","#                                                          corpus=corpus_all,\n","#                                                          listtokens=bigram_token_all,\n","#                                                          start=5, stop=60, step=5)\n","\n","# # affichage du graphe associ√© √† la recherche du nombre de topics\n","# plt.figure(figsize=(10,5))\n","# x = range(5, 60, 5)\n","# plt.plot(x, coherence_values)\n","# plt.xlabel(\"Nombre de topics\")\n","# plt.ylabel(\"Coherence \")\n","# #plt.legend((\"Valeurs de coh√©rencescoherence_values\"), loc='best')\n","# plt.show()\n","\n","\n","# num_topics=21 # nombre de topics\n","# num_words=50 # nombre de mots par topics\n","\n","\n","# lda_model_all = gensim.models.ldamulticore.LdaMulticore(\n","#     corpus=corpus_all,\n","#     num_topics=num_topics,\n","#     id2word=dictionary_all,\n","#     chunksize=100,\n","#     workers=7,\n","#     passes=10,\n","#     random_state=100,\n","#     eval_every = 1,\n","#     per_word_topics=True)\n","\n","\n","# print (\"Affichage des \",num_topics,\" diff√©rents topics pour le corpus BOW :\\n\")\n","# for idx, topic in lda_model_all.print_topics(-1,num_words):\n","#     print('Topic: {} Word: {}'.format(idx, topic))\n","\n","\n","\n","\n","# df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model_all, corpus=corpus_all, texts=data_brute.text)\n","\n","\n","# display(df_topic_sents_keywords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"NaE2oaoR_McT","outputId":"c4b4ba60-a359-471a-b464-1d79648867e0","executionInfo":{"status":"ok","timestamp":1682333609629,"user_tz":-120,"elapsed":1078505,"user":{"displayName":"Mathieu Cazeres","userId":"17539410092181857323"}}}},{"cell_type":"code","source":["import sys\n","from google.colab import drive\n","drive.mount('/content/drive')\n","my_local_drive = \"/content/drive/MyDrive/projet_ML/Projet_MachineLearning\"\n","# fonctions utilities (affichage, confusion, etc.)\n","sys.path.append(my_local_drive)\n","# Se positionner sur le r√©pertoire associ√©\n","%cd $my_local_drive\n","%pwd\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","\n","# fonctions utilities (affichage, confusion, etc.)\n","from Fonction.MyNLPUtilities import *\n","# fonctions utilities (fonction de clean, import etc etc)\n","from Fonction.myFonction import *\n","\n","from Fonction.AllModels import *\n","# librairies de gensim\n","import gensim\n","from gensim.utils import simple_preprocess\n","from gensim.models import CoherenceModel\n","from gensim.models import Phrases\n","from gensim.models.phrases import Phraser\n","from gensim import corpora\n","from gensim import models\n","\n","import re\n","import spacy\n","import gensim\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.corpus import wordnet\n","import gensim\n","from gensim.utils import simple_preprocess\n","from gensim.models import Phrases\n","from gensim.models.phrases import Phraser\n","from gensim import corpora\n","from gensim import models\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","\n","stop_words = set(stopwords.words('english'))\n","\n","nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n","#nlp = spacy.load('en', disable=['parser', 'ner'])\n","\n","\n","data_brute = pd.read_csv('./Data_equilibre/MyData_Sprint1et2.csv', sep=\",\")\n","# data_brute = data_brute.drop_duplicates()\n","print(data_brute['our rating'].value_counts())\n","\n","\n","def MyCleanTextsforLDA(texts,\n","                       min_count=1, # nombre d'apparitions minimale pour un bigram\n","                       threshold=2,\n","                       no_below=1, # nombre minimum d'apparitions pour √™tre dans le dictionnaire\n","                       no_above=0.5, # pourcentage maximal (sur la taille totale du corpus) pour filtrer\n","                       stop_words=stop_words\n","                       ):\n","\n","    allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\n","    sentences=texts.copy()\n","\n","    # suppression des caract√®res sp√©ciaux\n","    sentences = [re.sub(r'[^\\w\\s]', ' ', str(sentence)) for sentence in sentences]\n","    # suppression de tous les caract√®res uniques\n","    sentences = [re.sub(r'\\s+[a-zA-Z]\\s+', ' ', str(sentence)) for sentence in sentences]\n","    # substitution des espaces multiples par un seul espace\n","    sentences = [re.sub(r'\\s+', ' ', str(sentence), flags=re.I) for sentence in sentences]\n","\n","    # conversion en minuscule et split des mots dans les textes\n","    sentences = [sentence.lower().split() for sentence in sentences]\n","\n","    # utilisation de spacy pour ne retenir que les allowed_postags\n","    texts_out = []\n","    for sent in sentences:\n","        if len(sent) < (nlp.max_length): # si le texte est trop grand\n","            doc = nlp(\" \".join(sent))\n","            texts_out.append(\" \".join([token.lemma_ for token in doc if token.pos_ in allowed_postags]))\n","        else:\n","            texts_out.append(sent)\n","    sentences=texts_out\n","\n","    # suppression des stopwords\n","    words =[[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in sentences]\n","\n","\n","    # recherche des bigrammes\n","    bigram = Phrases(words, min_count, threshold,delimiter=' ')\n","    bigram_phraser = Phraser(bigram)\n","\n","\n","    # sauvergarde des tokens et des bigrammes\n","    bigram_token = []\n","    for sent in words:\n","        bigram_token.append(bigram_phraser[sent])\n","\n","\n","    # creation du vocabulaire\n","    dictionary = gensim.corpora.Dictionary(bigram_token)\n","\n","\n","    # il est possible de filtrer des mots en fonction de leur occurrence d'apparitions\n","    #dictionary.filter_extremes(no_below, no_above)\n","    # et de compacter le dictionnaire\n","    # dictionary.compactify()\n","    corpus = [dictionary.doc2bow(text) for text in bigram_token]\n","\n","    # recuperaction du tfidf plut√¥t que uniquement le bag of words\n","    tfidf = models.TfidfModel(corpus)\n","    corpus_tfidf = tfidf[corpus]\n","\n","    return corpus, corpus_tfidf, dictionary, bigram_token\n","\n","\n","\n","def get_best_coherence_values(corpus, dictionary, listtokens, start=5, stop=15, step=2):\n","    coherence_values = []\n","    model_list = []\n","    for num_topics in range(start, stop, step):\n","        lda_model = gensim.models.LdaMulticore(corpus=corpus,\n","                                               id2word=dictionary,\n","                                               num_topics=num_topics,\n","                                               random_state=100,\n","                                               chunksize=100,\n","                                               passes=10,\n","                                               workers=20,###\n","                                               eval_every=1,###\n","                                               alpha=0.01, ###\n","                                               eta=0.01,##\n","                                               per_word_topics=True)\n","\n","        coherence_model_lda = CoherenceModel(model=lda_model, texts=listtokens, dictionary=dictionary, coherence='c_v')\n","        model_list.append(lda_model)\n","        coherence_values.append(coherence_model_lda.get_coherence())\n","    return model_list, coherence_values\n","\n","\n","\n","\n","\n","\n","\n","def format_topics_sentences(ldamodel, corpus, texts):\n","    # Initialisation du dataframe de sortie\n","    sent_topics_df = pd.DataFrame()\n","\n","    # Recherche le topic dominant pour chaque document\n","    for i, row_list in enumerate(ldamodel[corpus]):\n","        row = row_list[0] if ldamodel.per_word_topics else row_list\n","\n","        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n","        # Donne le topic dominant, le pourcentage de contribution\n","        # et les mots cl√©s pour chaque document\n","        for j, (topic_num, prop_topic) in enumerate(row):\n","            if j == 0:  # => topic dominant\n","                wp = ldamodel.show_topic(topic_num)\n","                topic_keywords = \", \".join([word for word, prop in wp])\n","                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n","            else:\n","                break\n","    sent_topics_df.columns = ['topic_dominant', 'pourcentage_contrib', 'topic_keywords']\n","\n","    # Ajout du texte original √† la fin de la sortie\n","    contents = pd.Series(texts)\n","    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n","    return(sent_topics_df)\n","\n","\n","stop = stopwords.words('english')\n","\n","\n","# enrichissement des stopwords \n","stop.extend(['always','try','go','get','say','make','would','really',\n","                  'like','came','got'])\n","\n","\n","\n","\n","\n","# ce code est inspir√© de \n","# https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n","def compute_coherence_values(corpus, dictionary, listtokens, k, alpha, eta):\n","    \n","    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n","                                           id2word=dictionary,\n","                                           num_topics=k, \n","                                           random_state=100,\n","                                           chunksize=100,\n","                                           passes=10,\n","                                           alpha=alpha,\n","                                           eta=eta,\n","                                           workers=7,###\n","                                           eval_every=1,###\n","                                           per_word_topics=True)\n","    \n","    coherence_model_lda = CoherenceModel(model=lda_model, texts=listtokens, dictionary=dictionary, coherence='c_v')\n","    \n","    return coherence_model_lda.get_coherence()\n","\n","def MyGridSearchLda (corpus,listtokens,dictionnary,nb_topics,alpha,beta,verbose=1):\n","        \n","    grid = {}\n","    model_results = {'topics': [],\n","                     'alpha': [],\n","                     'eta': [],\n","                     'coherence': []\n","                    }\n","    # iteration sur le nombre de topics\n","    for k in nb_topics:\n","        # iteration sur les valeurs d'alpha\n","        for a in alpha:\n","            # iteration sur les valeurs de eta\n","            for e in eta:\n","                # calcul du score de coherence\n","                cv = compute_coherence_values(corpus=corpus, \n","                                              dictionary=dictionary,\n","                                              listtokens=listtokens,\n","                                              k=k, alpha=a, eta=e)\n","                if verbose==1:\n","                    print ('topics:', k, ' alpha: %0.3f  eta: %0.3f  coherence: %0.3f'%(a,e,cv))\n","                        \n","                # sauvegarde des r√©sultats\n","                model_results['topics'].append(k)\n","                model_results['alpha'].append(a)\n","                model_results['eta'].append(e)\n","                model_results['coherence'].append(cv)\n","                  \n","    df_result=pd.DataFrame(model_results)\n","    df_result = df_result.sort_values('coherence',ascending=False)\n","    df_result.reset_index(drop=True, inplace=True)\n","    return df_result\n","\n","\n","data_brute.title_text = data_brute.title + data_brute.text\n","\n","\n","corpus, corpus_tfidf, dictionary, bigram_token=MyCleanTextsforLDA(data_brute.title_text,stop_words=stop_words)\n","# variation du nombre de topics\n","min_topics = 14\n","max_topics = 20\n","step_size = 2\n","nb_topics = range(min_topics, max_topics, step_size)\n","# variation d'alpha\n","alpha = list(np.arange(1, 2.5, 0.3))\n","# variation de eta\n","eta = list(np.arange(1, 2.5, 0.3))\n","print (\"Extraction des meilleurs param√®tres pour le corpus via BOW : \")\n","df_result=MyGridSearchLda (corpus,bigram_token,dictionary,nb_topics,alpha,eta,verbose=1)  \n","display (df_result)\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GX2UEfyz_ZZ5","outputId":"cd63a3bb-eb0e-4628-b15f-7412cfcc996b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/projet_ML/Projet_MachineLearning\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["false      210\n","true       210\n","mixture    210\n","other      210\n","Name: our rating, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-1-da4e05460f6a>:238: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n","  data_brute.title_text = data_brute.title + data_brute.text\n"]},{"output_type":"stream","name":"stdout","text":["Extraction des meilleurs param√®tres pour le corpus via BOW : \n","topics: 14  alpha: 1.000  eta: 1.000  coherence: 0.432\n","topics: 14  alpha: 1.000  eta: 1.300  coherence: 0.324\n","topics: 14  alpha: 1.000  eta: 1.600  coherence: 0.425\n","topics: 14  alpha: 1.000  eta: 1.900  coherence: 0.413\n","topics: 14  alpha: 1.000  eta: 2.200  coherence: 0.376\n","topics: 14  alpha: 1.300  eta: 1.000  coherence: 0.467\n","topics: 14  alpha: 1.300  eta: 1.300  coherence: 0.448\n","topics: 14  alpha: 1.300  eta: 1.600  coherence: 0.451\n","topics: 14  alpha: 1.300  eta: 1.900  coherence: 0.464\n","topics: 14  alpha: 1.300  eta: 2.200  coherence: 0.477\n","topics: 14  alpha: 1.600  eta: 1.000  coherence: 0.431\n","topics: 14  alpha: 1.600  eta: 1.300  coherence: 0.515\n","topics: 14  alpha: 1.600  eta: 1.600  coherence: 0.390\n","topics: 14  alpha: 1.600  eta: 1.900  coherence: 0.396\n","topics: 14  alpha: 1.600  eta: 2.200  coherence: 0.484\n","topics: 14  alpha: 1.900  eta: 1.000  coherence: 0.342\n","topics: 14  alpha: 1.900  eta: 1.300  coherence: 0.372\n","topics: 14  alpha: 1.900  eta: 1.600  coherence: 0.339\n","topics: 14  alpha: 1.900  eta: 1.900  coherence: 0.481\n","topics: 14  alpha: 1.900  eta: 2.200  coherence: 0.415\n","topics: 14  alpha: 2.200  eta: 1.000  coherence: 0.452\n","topics: 14  alpha: 2.200  eta: 1.300  coherence: 0.381\n","topics: 14  alpha: 2.200  eta: 1.600  coherence: 0.411\n","topics: 14  alpha: 2.200  eta: 1.900  coherence: 0.462\n","topics: 14  alpha: 2.200  eta: 2.200  coherence: 0.395\n","topics: 16  alpha: 1.000  eta: 1.000  coherence: 0.447\n","topics: 16  alpha: 1.000  eta: 1.300  coherence: 0.451\n","topics: 16  alpha: 1.000  eta: 1.600  coherence: 0.414\n","topics: 16  alpha: 1.000  eta: 1.900  coherence: 0.413\n","topics: 16  alpha: 1.000  eta: 2.200  coherence: 0.519\n","topics: 16  alpha: 1.300  eta: 1.000  coherence: 0.387\n","topics: 16  alpha: 1.300  eta: 1.300  coherence: 0.454\n","topics: 16  alpha: 1.300  eta: 1.600  coherence: 0.466\n","topics: 16  alpha: 1.300  eta: 1.900  coherence: 0.427\n"]}]},{"cell_type":"code","source":["\n","num_topics=20 # nombre de topics\n","num_words=30 # nombre de mots par topics\n","\n","\n","lda_model_all = gensim.models.ldamulticore.LdaMulticore(\n","    corpus=corpus_all,\n","    num_topics=num_topics,\n","    id2word=dictionary_all,\n","    chunksize=400,\n","    workers=7,\n","    passes=20,\n","    random_state=100,\n","    eval_every = 1,\n","    per_word_topics=True)\n","\n","\n","print (\"Affichage des \",num_topics,\" diff√©rents topics pour le corpus BOW :\\n\")\n","for idx, topic in lda_model_all.print_topics(-1,num_words):\n","    print('Topic: {} Word: {}'.format(idx, topic))\n","\n","\n","\n","\n","df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model_all, corpus=corpus_all, texts=data_brute.text)\n","\n","\n","display(df_topic_sents_keywords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":849},"id":"64L8eegiRaoI","executionInfo":{"status":"ok","timestamp":1682270700386,"user_tz":-120,"elapsed":44531,"user":{"displayName":"Mathieu Cazeres","userId":"17539410092181857323"}},"outputId":"e6d72afa-7246-4d16-f9e9-0b713570725d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Affichage des  20  diff√©rents topics pour le corpus BOW :\n","\n","Topic: 0 Word: 0.004*\"self employ\" + 0.003*\"national insurance\" + 0.003*\"sst\" + 0.003*\"also\" + 0.002*\"datum\" + 0.002*\"show\" + 0.002*\"great barrier\" + 0.002*\"reef\" + 0.002*\"program\" + 0.002*\"scholar\" + 0.002*\"cool\" + 0.002*\"aim\" + 0.002*\"include\" + 0.002*\"oc\" + 0.002*\"sea surface\" + 0.002*\"university\" + 0.002*\"alien\" + 0.002*\"voter roll\" + 0.002*\"climate sensitivity\" + 0.001*\"latitude\" + 0.001*\"state\" + 0.001*\"student\" + 0.001*\"hank\" + 0.001*\"pilf\" + 0.001*\"datum centre\" + 0.001*\"gift\" + 0.001*\"australian current\" + 0.001*\"take\" + 0.001*\"month\" + 0.001*\"report\"\n","Topic: 1 Word: 0.003*\"report\" + 0.003*\"neighborhood\" + 0.003*\"human right\" + 0.003*\"case\" + 0.003*\"salvadoran\" + 0.003*\"police\" + 0.003*\"include\" + 0.003*\"kill\" + 0.003*\"interview\" + 0.003*\"victim\" + 0.003*\"also\" + 0.003*\"authority\" + 0.002*\"even\" + 0.002*\"tell\" + 0.002*\"people\" + 0.002*\"gang member\" + 0.002*\"know\" + 0.002*\"accord\" + 0.002*\"gang\" + 0.002*\"country\" + 0.002*\"deportee\" + 0.002*\"year\" + 0.002*\"deportation\" + 0.002*\"crime\" + 0.002*\"person\" + 0.002*\"flee\" + 0.002*\"return\" + 0.002*\"watch\" + 0.002*\"officer\" + 0.002*\"deport\"\n","Topic: 2 Word: 0.005*\"year\" + 0.003*\"also\" + 0.003*\"report\" + 0.002*\"time\" + 0.002*\"country\" + 0.002*\"government\" + 0.002*\"show\" + 0.002*\"change\" + 0.002*\"world\" + 0.002*\"even\" + 0.002*\"work\" + 0.002*\"use\" + 0.002*\"well\" + 0.002*\"child\" + 0.002*\"come\" + 0.002*\"new\" + 0.002*\"think\" + 0.002*\"include\" + 0.002*\"give\" + 0.002*\"climate change\" + 0.002*\"school\" + 0.002*\"take\" + 0.002*\"need\" + 0.002*\"see\" + 0.002*\"increase\" + 0.002*\"way\" + 0.002*\"scientist\" + 0.001*\"call\" + 0.001*\"know\" + 0.001*\"people\"\n","Topic: 3 Word: 0.005*\"people\" + 0.005*\"know\" + 0.004*\"think\" + 0.003*\"president\" + 0.003*\"time\" + 0.003*\"also\" + 0.003*\"come\" + 0.003*\"report\" + 0.003*\"take\" + 0.003*\"election\" + 0.003*\"trump\" + 0.003*\"believe\" + 0.003*\"man\" + 0.002*\"country\" + 0.002*\"call\" + 0.002*\"work\" + 0.002*\"right\" + 0.002*\"part\" + 0.002*\"see\" + 0.002*\"want\" + 0.002*\"well\" + 0.002*\"state\" + 0.002*\"first\" + 0.002*\"vote\" + 0.002*\"look\" + 0.002*\"point\" + 0.002*\"woman\" + 0.002*\"government\" + 0.002*\"day\" + 0.002*\"year\"\n","Topic: 4 Word: 0.005*\"year\" + 0.004*\"work\" + 0.003*\"state\" + 0.003*\"people\" + 0.003*\"bill\" + 0.003*\"report\" + 0.003*\"time\" + 0.002*\"government\" + 0.002*\"include\" + 0.002*\"also\" + 0.002*\"service\" + 0.002*\"affordable housing\" + 0.002*\"take\" + 0.001*\"school\" + 0.001*\"need\" + 0.001*\"overflow\" + 0.001*\"increase\" + 0.001*\"life\" + 0.001*\"high street\" + 0.001*\"cost\" + 0.001*\"impact statement\" + 0.001*\"early intervention\" + 0.001*\"see\" + 0.001*\"live\" + 0.001*\"income\" + 0.001*\"level\" + 0.001*\"mask\" + 0.001*\"household\" + 0.001*\"help\" + 0.001*\"food stamp\"\n","Topic: 5 Word: 0.004*\"people\" + 0.004*\"time\" + 0.004*\"know\" + 0.003*\"report\" + 0.003*\"year\" + 0.003*\"also\" + 0.003*\"state\" + 0.002*\"country\" + 0.002*\"come\" + 0.002*\"call\" + 0.002*\"work\" + 0.002*\"include\" + 0.002*\"many\" + 0.002*\"well\" + 0.002*\"take\" + 0.002*\"change\" + 0.002*\"want\" + 0.002*\"follow\" + 0.002*\"number\" + 0.002*\"case\" + 0.002*\"president\" + 0.002*\"today\" + 0.002*\"back\" + 0.002*\"way\" + 0.002*\"need\" + 0.002*\"give\" + 0.002*\"first\" + 0.002*\"thing\" + 0.002*\"government\" + 0.002*\"new\"\n","Topic: 6 Word: 0.003*\"use\" + 0.003*\"year\" + 0.003*\"chick pizza\" + 0.003*\"party work\" + 0.003*\"also\" + 0.003*\"include\" + 0.003*\"time\" + 0.003*\"state\" + 0.003*\"pizza party\" + 0.002*\"law\" + 0.002*\"receipt attach\" + 0.002*\"people\" + 0.002*\"right\" + 0.002*\"come\" + 0.002*\"report\" + 0.002*\"tunnel\" + 0.002*\"know\" + 0.002*\"case\" + 0.002*\"work\" + 0.002*\"think\" + 0.002*\"joint enterprise\" + 0.002*\"work chick\" + 0.002*\"asc food\" + 0.002*\"see\" + 0.002*\"far\" + 0.002*\"storm\" + 0.001*\"fire\" + 0.001*\"day\" + 0.001*\"employee\" + 0.001*\"walker\"\n","Topic: 7 Word: 0.006*\"people\" + 0.004*\"year\" + 0.002*\"show\" + 0.002*\"virus\" + 0.002*\"need\" + 0.002*\"use\" + 0.002*\"time\" + 0.002*\"find\" + 0.002*\"know\" + 0.002*\"day\" + 0.002*\"report\" + 0.002*\"order\" + 0.002*\"work\" + 0.002*\"trump\" + 0.002*\"vaccine\" + 0.002*\"covid\" + 0.001*\"warn\" + 0.001*\"public health\" + 0.001*\"child\" + 0.001*\"right\" + 0.001*\"bill\" + 0.001*\"accord\" + 0.001*\"take\" + 0.001*\"price\" + 0.001*\"mother\" + 0.001*\"also\" + 0.001*\"month\" + 0.001*\"family\" + 0.001*\"government\" + 0.001*\"well\"\n","Topic: 8 Word: 0.003*\"case\" + 0.003*\"report\" + 0.002*\"time\" + 0.002*\"covid case\" + 0.002*\"vaccination status\" + 0.002*\"work\" + 0.002*\"intensive care\" + 0.002*\"state\" + 0.002*\"people\" + 0.002*\"fact\" + 0.002*\"show\" + 0.002*\"health\" + 0.002*\"year old\" + 0.002*\"black lung\" + 0.001*\"disease\" + 0.001*\"patient\" + 0.001*\"activity\" + 0.001*\"mental health\" + 0.001*\"deer\" + 0.001*\"practice\" + 0.001*\"datum\" + 0.001*\"public health\" + 0.001*\"year\" + 0.001*\"child pass\" + 0.001*\"coal miner\" + 0.001*\"well know\" + 0.001*\"vaccination rate\" + 0.001*\"well\" + 0.001*\"possible\" + 0.001*\"accord\"\n","Topic: 9 Word: 0.005*\"vitamin\" + 0.004*\"state\" + 0.004*\"also\" + 0.003*\"people\" + 0.003*\"open new\" + 0.003*\"time\" + 0.002*\"death\" + 0.002*\"system\" + 0.002*\"include\" + 0.002*\"heat\" + 0.002*\"still\" + 0.002*\"tab\" + 0.002*\"accord\" + 0.002*\"long term\" + 0.002*\"work\" + 0.002*\"death certificate\" + 0.001*\"new\" + 0.001*\"nursing home\" + 0.001*\"call\" + 0.001*\"percent\" + 0.001*\"country\" + 0.001*\"test\" + 0.001*\"find\" + 0.001*\"take\" + 0.001*\"die\" + 0.001*\"energy\" + 0.001*\"facility\" + 0.001*\"care facility\" + 0.001*\"pcr test\" + 0.001*\"care\"\n","Topic: 10 Word: 0.004*\"people\" + 0.004*\"year\" + 0.002*\"state\" + 0.002*\"school\" + 0.002*\"also\" + 0.002*\"see\" + 0.002*\"care\" + 0.002*\"come\" + 0.002*\"use\" + 0.002*\"child\" + 0.002*\"time\" + 0.002*\"work\" + 0.002*\"find\" + 0.002*\"country\" + 0.002*\"government\" + 0.002*\"death\" + 0.002*\"include\" + 0.002*\"day\" + 0.002*\"many\" + 0.002*\"even\" + 0.002*\"family\" + 0.002*\"life\" + 0.002*\"nhs\" + 0.002*\"need\" + 0.002*\"right\" + 0.002*\"case\" + 0.001*\"take\" + 0.001*\"know\" + 0.001*\"claim\" + 0.001*\"report\"\n","Topic: 11 Word: 0.004*\"state\" + 0.003*\"need\" + 0.002*\"year\" + 0.002*\"report\" + 0.002*\"work\" + 0.002*\"study\" + 0.002*\"show\" + 0.002*\"people\" + 0.002*\"include\" + 0.002*\"bill gate\" + 0.002*\"number\" + 0.002*\"call\" + 0.002*\"government\" + 0.002*\"use\" + 0.001*\"well\" + 0.001*\"day\" + 0.001*\"case\" + 0.001*\"house\" + 0.001*\"contact tracing\" + 0.001*\"job\" + 0.001*\"child\" + 0.001*\"coronavirus outbreak\" + 0.001*\"time\" + 0.001*\"last year\" + 0.001*\"place\" + 0.001*\"public health\" + 0.001*\"give\" + 0.001*\"support\" + 0.001*\"leave\" + 0.001*\"also\"\n","Topic: 12 Word: 0.006*\"business\" + 0.005*\"export\" + 0.004*\"support\" + 0.004*\"trade\" + 0.004*\"include\" + 0.003*\"work\" + 0.003*\"market\" + 0.003*\"government\" + 0.003*\"new\" + 0.003*\"sector\" + 0.003*\"exporter\" + 0.003*\"world\" + 0.002*\"footnote\" + 0.002*\"also\" + 0.002*\"ice shelf\" + 0.002*\"year\" + 0.002*\"country\" + 0.002*\"programme\" + 0.002*\"opportunity\" + 0.002*\"agreement\" + 0.002*\"well\" + 0.002*\"ensure\" + 0.002*\"increase\" + 0.002*\"economy\" + 0.002*\"growth\" + 0.002*\"service\" + 0.002*\"provide\" + 0.002*\"need\" + 0.002*\"digital\" + 0.001*\"offer\"\n","Topic: 13 Word: 0.005*\"people\" + 0.004*\"work\" + 0.004*\"vaccine\" + 0.003*\"use\" + 0.003*\"year\" + 0.003*\"time\" + 0.003*\"well\" + 0.003*\"see\" + 0.003*\"case\" + 0.003*\"also\" + 0.003*\"country\" + 0.002*\"need\" + 0.002*\"sar cov\" + 0.002*\"virus\" + 0.002*\"spike protein\" + 0.002*\"vaccination\" + 0.002*\"covid vaccine\" + 0.002*\"even\" + 0.002*\"many\" + 0.002*\"know\" + 0.002*\"take\" + 0.002*\"day\" + 0.002*\"disease\" + 0.002*\"local publicly\" + 0.002*\"electric utility\" + 0.002*\"come\" + 0.002*\"world\" + 0.002*\"death\" + 0.002*\"look\" + 0.002*\"number\"\n","Topic: 14 Word: 0.004*\"country\" + 0.003*\"people\" + 0.003*\"vaccine\" + 0.003*\"time\" + 0.002*\"child\" + 0.002*\"report\" + 0.002*\"use\" + 0.002*\"covid vaccine\" + 0.002*\"dog\" + 0.002*\"show\" + 0.002*\"state\" + 0.002*\"take\" + 0.002*\"know\" + 0.002*\"also\" + 0.002*\"business scandal\" + 0.002*\"dose\" + 0.002*\"include\" + 0.002*\"year\" + 0.002*\"day\" + 0.001*\"video\" + 0.001*\"tell\" + 0.001*\"vaccination\" + 0.001*\"covid\" + 0.001*\"current\" + 0.001*\"work\" + 0.001*\"datum\" + 0.001*\"authority\" + 0.001*\"request\" + 0.001*\"part\" + 0.001*\"least\"\n","Topic: 15 Word: 0.003*\"use\" + 0.003*\"day\" + 0.003*\"state\" + 0.002*\"election worker\" + 0.002*\"work\" + 0.002*\"child\" + 0.002*\"result\" + 0.002*\"rate\" + 0.002*\"mask\" + 0.002*\"dhs\" + 0.002*\"even\" + 0.002*\"people\" + 0.002*\"case\" + 0.002*\"positive test\" + 0.002*\"mine\" + 0.002*\"test result\" + 0.002*\"covid\" + 0.002*\"right\" + 0.002*\"trump\" + 0.002*\"however\" + 0.002*\"school\" + 0.002*\"study\" + 0.002*\"voter\" + 0.002*\"issue\" + 0.001*\"number\" + 0.001*\"election day\" + 0.001*\"test\" + 0.001*\"test rate\" + 0.001*\"give\" + 0.001*\"patient\"\n","Topic: 16 Word: 0.004*\"year\" + 0.003*\"reef\" + 0.003*\"people\" + 0.003*\"child\" + 0.002*\"time\" + 0.002*\"woman\" + 0.002*\"hard coral\" + 0.002*\"cover\" + 0.002*\"coral cover\" + 0.002*\"however\" + 0.002*\"know\" + 0.002*\"vaccination\" + 0.002*\"use\" + 0.002*\"point\" + 0.002*\"see\" + 0.002*\"find\" + 0.002*\"state\" + 0.002*\"government\" + 0.002*\"covid\" + 0.002*\"figure\" + 0.001*\"right\" + 0.001*\"reef survey\" + 0.001*\"report\" + 0.001*\"study\" + 0.001*\"even\" + 0.001*\"want\" + 0.001*\"part\" + 0.001*\"crown thorn\" + 0.001*\"also\" + 0.001*\"travel\"\n","Topic: 17 Word: 0.006*\"vaccine\" + 0.005*\"people\" + 0.003*\"covid\" + 0.003*\"virus\" + 0.003*\"infection\" + 0.003*\"sar cov\" + 0.003*\"report\" + 0.002*\"see\" + 0.002*\"come\" + 0.002*\"also\" + 0.002*\"seek relief\" + 0.002*\"scorch saharan\" + 0.002*\"heatwave picture\" + 0.002*\"government\" + 0.002*\"country\" + 0.002*\"coronavirus\" + 0.002*\"include\" + 0.002*\"show\" + 0.002*\"many\" + 0.002*\"way\" + 0.002*\"time\" + 0.002*\"new\" + 0.002*\"immune system\" + 0.002*\"even\" + 0.001*\"need\" + 0.001*\"antibody\" + 0.001*\"death\" + 0.001*\"disease\" + 0.001*\"work\" + 0.001*\"well\"\n","Topic: 18 Word: 0.012*\"vaccine\" + 0.004*\"people\" + 0.003*\"study\" + 0.002*\"also\" + 0.002*\"report\" + 0.002*\"covid\" + 0.002*\"cervical cancer\" + 0.002*\"delta variant\" + 0.002*\"death\" + 0.002*\"show\" + 0.002*\"child\" + 0.002*\"include\" + 0.002*\"virus\" + 0.002*\"ip address\" + 0.002*\"vaccination\" + 0.002*\"see\" + 0.002*\"variant\" + 0.002*\"year\" + 0.002*\"delta\" + 0.002*\"datum\" + 0.002*\"year age\" + 0.002*\"result\" + 0.002*\"state\" + 0.002*\"vaccinate\" + 0.002*\"school\" + 0.002*\"tell\" + 0.001*\"group\" + 0.001*\"month\" + 0.001*\"know\" + 0.001*\"high\"\n","Topic: 19 Word: 0.006*\"year\" + 0.005*\"change\" + 0.005*\"climate change\" + 0.003*\"see\" + 0.003*\"global warming\" + 0.003*\"world\" + 0.003*\"temperature\" + 0.003*\"warming\" + 0.003*\"even\" + 0.003*\"climate\" + 0.003*\"scientist\" + 0.003*\"also\" + 0.003*\"rise\" + 0.003*\"water\" + 0.002*\"sea level\" + 0.002*\"increase\" + 0.002*\"tipping point\" + 0.002*\"warm\" + 0.002*\"call\" + 0.002*\"cause\" + 0.002*\"state\" + 0.002*\"level\" + 0.002*\"new\" + 0.002*\"time\" + 0.002*\"ocean\" + 0.002*\"mean\" + 0.002*\"example\" + 0.002*\"show\" + 0.002*\"study\" + 0.002*\"reef\"\n"]},{"output_type":"display_data","data":{"text/plain":["     topic_dominant  pourcentage_contrib  \\\n","0                 4               0.9947   \n","1                 6               0.6176   \n","2                18               0.5094   \n","3                 5               0.9168   \n","4                 2               0.7710   \n","..              ...                  ...   \n","835               0               0.9923   \n","836              18               0.7623   \n","837              14               0.9980   \n","838               2               0.8098   \n","839              11               0.9934   \n","\n","                                        topic_keywords  \\\n","0    year, work, state, people, bill, report, time,...   \n","1    use, year, chick pizza, party work, also, incl...   \n","2    vaccine, people, study, also, report, covid, c...   \n","3    people, time, know, report, year, also, state,...   \n","4    year, also, report, time, country, government,...   \n","..                                                 ...   \n","835  self employ, national insurance, sst, also, da...   \n","836  vaccine, people, study, also, report, covid, c...   \n","837  country, people, vaccine, time, child, report,...   \n","838  year, also, report, time, country, government,...   \n","839  state, need, year, report, work, study, show, ...   \n","\n","                                                  text  \n","0    Urgent action needed to save ‚Äòdying‚Äô high stre...  \n","1    Denying 2000 years of the Medieval Warm Period...  \n","2    Dr. V.A. Shiva Ayyadurai, M.I.T. PhD, the Inve...  \n","3     Special Operations SOF units including 4,000 ...  \n","4    Bernie Sanders, an independent, represents Ver...  \n","..                                                 ...  \n","835  Rises in National Insurance Contributions NICS...  \n","836  U.S. Government Finally Admits Marijuana Reall...  \n","837  The nosediving security situation in the count...  \n","838  Coronavirus may be sexually transmitted and ca...  \n","839  A new study by the U.S. CDC raises the suspici...  \n","\n","[840 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-44f3813f-1dd6-4334-8fa0-505db8ab33d0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topic_dominant</th>\n","      <th>pourcentage_contrib</th>\n","      <th>topic_keywords</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>0.9947</td>\n","      <td>year, work, state, people, bill, report, time,...</td>\n","      <td>Urgent action needed to save ‚Äòdying‚Äô high stre...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6</td>\n","      <td>0.6176</td>\n","      <td>use, year, chick pizza, party work, also, incl...</td>\n","      <td>Denying 2000 years of the Medieval Warm Period...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>18</td>\n","      <td>0.5094</td>\n","      <td>vaccine, people, study, also, report, covid, c...</td>\n","      <td>Dr. V.A. Shiva Ayyadurai, M.I.T. PhD, the Inve...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>0.9168</td>\n","      <td>people, time, know, report, year, also, state,...</td>\n","      <td>Special Operations SOF units including 4,000 ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>0.7710</td>\n","      <td>year, also, report, time, country, government,...</td>\n","      <td>Bernie Sanders, an independent, represents Ver...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>835</th>\n","      <td>0</td>\n","      <td>0.9923</td>\n","      <td>self employ, national insurance, sst, also, da...</td>\n","      <td>Rises in National Insurance Contributions NICS...</td>\n","    </tr>\n","    <tr>\n","      <th>836</th>\n","      <td>18</td>\n","      <td>0.7623</td>\n","      <td>vaccine, people, study, also, report, covid, c...</td>\n","      <td>U.S. Government Finally Admits Marijuana Reall...</td>\n","    </tr>\n","    <tr>\n","      <th>837</th>\n","      <td>14</td>\n","      <td>0.9980</td>\n","      <td>country, people, vaccine, time, child, report,...</td>\n","      <td>The nosediving security situation in the count...</td>\n","    </tr>\n","    <tr>\n","      <th>838</th>\n","      <td>2</td>\n","      <td>0.8098</td>\n","      <td>year, also, report, time, country, government,...</td>\n","      <td>Coronavirus may be sexually transmitted and ca...</td>\n","    </tr>\n","    <tr>\n","      <th>839</th>\n","      <td>11</td>\n","      <td>0.9934</td>\n","      <td>state, need, year, report, work, study, show, ...</td>\n","      <td>A new study by the U.S. CDC raises the suspici...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>840 rows √ó 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44f3813f-1dd6-4334-8fa0-505db8ab33d0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-44f3813f-1dd6-4334-8fa0-505db8ab33d0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-44f3813f-1dd6-4334-8fa0-505db8ab33d0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["\n","print(df_topic_sents_keywords['topic_keywords'][837])\n","print(df_topic_sents_keywords['text'][837])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QtrxMMiTj_qS","executionInfo":{"status":"ok","timestamp":1682270800474,"user_tz":-120,"elapsed":4,"user":{"displayName":"Mathieu Cazeres","userId":"17539410092181857323"}},"outputId":"c9679dd1-aeed-4bfb-d71f-c8b1e2d14aad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["country, people, vaccine, time, child, report, use, covid vaccine, dog, show\n","The nosediving security situation in the country is increasingly putting President Muhammadu Buhari under pressure as prominent Nigerians, among whom are governors, former political office holders, clerics and Nobel Laureate, Professor Wole Soyinka, have started to speak out in condemnation of his alleged inaction. The past two weeks have particularly been traumatic for the country, with killings, abductions and attacks on communities and security agencies, especially as killing of police officers continues unabated. Within the period, bandits operating in Kaduna State invaded a private institution in the State, Greenfield University in Chikun Local Government Area, abducted more than 20 students and killed a staff during the attack. In a gruesome move, the bandits, who asked for N800 million ransom, have killed five of the students to show that they meant business. During the period also, scores of innocent Nigerians were killed in Zamfara State as Boko Haram attempted to take over Geidam in Yobe State and Mainok in Borno State, with the Nigerian military fighting desperately to retake them, albeit at a cost, as some men and officers were lost during the battle. Not done, bandits also attacked and abducted students of the Federal University of Agriculture, Markurdi, the Benue State capital, early in the week. Nothing has been heard about the fate of the students. This is apart from a revelation from the Governor of the State, Samuel Ortom that about 70 residents of the state have been killed in two weeks. The situation in Niger State is fast becoming hopeless, as two LGAs, Munya and Shiroro, have practically become bandits‚Äô killing fields. This was before a shocking revelation by the state governor, Abubakar Sani Bello that Boko Haram insurgents have infiltrated the state, hoisting their flag in Kaure in Munya LGA, an indication that they have declared a caliphate in the area. Also down South, the situation in the South-East geopolitical zone is increasing calling for concerns, as no day passes without reports of attacks on the police formations and personnel. What makes the South-East situation more alarming is that the operation of ‚Äògunmen‚Äô in the zone have mainly focused on security agents, in what reminds Nigerians about the formative days of the Boko Haram insurgency. This has no doubt raised comcerns in several circles of an evolving insurgency in Igboland, a situation many believe Nigeria may not be able to cope with, especially with the current insurgency in North-East and banditry in the North-West and North Central. Realising that the security situation in the country was practically spiralling out of control, prominent Nigerians decided to speak out, putting further pressure on the Buhari administration, which many Nigerians said has proven unable to proffer solution to the hydra headed security challenges in the country. In a rather frustrated outburst, Nasir el-Rufai, Governor of Kaduna State, who has constantly shown his disgust for the bandits operating in his state, pointedly declared that what the bandits and other criminal elements terrorising the country deserve is deaths. He said, ‚Äúkill them all‚Äù. According to him, no one staying in the forests is innocent and what they deserve is death, opening a floodgate of intervention, angry outbursts and advice from prominent Nigerians. Respected Nobel Laureate, Professor Wole Soyinka, shortly after the killing of three of the abducted students of Greenfield University, pointedly told President Buhari to swallow his pride and seek for help! ‚ÄúSeek Help. Stop Improvising with Human Lives. Youth ‚Äì that is, the future ‚Äì should not serve as ritual offering on the altar of a failing State‚Äù, he said in a statement on Saturday. According to Soyinka, Nigeria is at war but the government continues to pretend that ‚Äúthese are mere birth-pangs of a glorious entity‚Äù. He however, said the current situation in the country suggests death throes, adding, ‚ÄúVultures and undertakers hover patiently but with full confidence.‚Äù ‚ÄúThe dogs of war stopped merely baying years ago. Again and again, they have sunk their fangs into the jugular of this nation. The plague called COVID has met its match on the earth of some nation space once known as Nigeria‚Äù, Soyinka painted a scary picture of the Nigerian situation. The ruling All Progressives Congress (APC), perhaps to show that it is a party with a soul, admitted, albeit for the first time that insecurity is real in the country. Before admitting what other Nigerians have always known in a statement by its National Secretary, Senator John James Akpanudoedehe, the APC had always beaten its chest that the Buhari administration has improved security in the country tremendously since coming into office in 2015. They also claimed that the security situation in the country had improved from what it used to be under the Goodluck Jonathan administration that ended on May 29, 2015. However, the party said: ‚ÄúThe issue of insecurity in the country has found expression in terrorist and criminal activities of Boko Haram, bandits, kidnappers, rustlers and recently the highly condemnable attacks on security formations in some states. ‚ÄúThese are current realities and the APC will not playing politics with matters of life and our collective wellbeing as a nation.‚Äù For many Nigerians, the admittance by the ruling party that all is not well with the country, may after all spur the government of the nation into action. This is because of the belief that the party and the country has always lived in denial of the actual situation in the country. Majority of Nigerians who watched the viral video of Niger State Governor, Abubakar Sani Bello talking about the situation in his state cut a pitiable sight of a man who is frustrated, not just for his inability to secure his people but also knowing that a greater evil, Boko Haram has taken residence right in his backyard. The Governor, in the video, while he went visiting about 3000 Internally Displaced Persons (IDPs) taking refugee at a school in Minna, the state capital, said that Boko Haram insurgents are already in the state. He said: ‚ÄúI am confirming that there are Boko Haram elements in Niger State, around Kaure. ‚ÄúI just heard that they‚Äôve already hoisted their flag in Kaure, which means they‚Äôve taken over the territory and this is what I have been engaging the FG with, and unfortunately it has now gotten to this stage that if care is not taken, not even Abuja is safe. ‚ÄúThey‚Äôve taken over the territory, they‚Äôve installed their flag. I am confirming that now. They‚Äôve taken over the wives of people by force. ‚ÄúBoko Haram elements are trying to use these areas as their home just like they did in Sambisa.‚Äù In what seems like a double speak, Governor Bello said: ‚ÄúI have not lost hope from the federal government but I am not waiting for anyone anymore.‚Äù DAILY POST recalls that Niger State has had history with the Boko Haram insurgency, as the state was at a time used as a launching pad for attempted incursions into Abuja in the hey days of the group. Joining his voice to calls by the Buhari administration to seek for help in tackling the declining security situation in the country, the Immediate-past Senate President, Bukola Saraki, on Tuesday, said the President needs help and he must seek for one. Saraki, who said it was obvious that Buhari was already overwhelmed, said the situation ‚Äúcannot continue‚Äù and ‚Äúcannot become Nigeria‚Äôs new normal‚Äù. He said: ‚ÄúIt is obvious that President Muhammadu Buhari and the All Progressives Congress government need help. They have been overwhelmed by the situation and they sure need assistance from all. Thus, I urge Mr. President to seek help wherever it can be given. This matter has gone beyond what the government can handle alone. The President should know that calling for help in our present situation is not a sign of weakness.‚Äù According to Saraki, President Buhari needs to bring together all former Presidents and heads of state, serving and former chief justices, serving and former presiding officers of the National Assembly, serving and former heads of security agencies, traditional rulers with relevant experience, leaders of the private sector, development partners, friends of Nigeria in the international community and all others who can help in finding solutions to the problem at hand. ‚ÄúThe meeting must hold expeditiously and must be followed by immediate actions. I know there are many people who believe that the fact that this suggestion is coming from a source outside government is a good reason for the President to ignore it. I think the attitude this time around must be different. This is definitely not a time for partisanship or for people to play politics with the lives of the citizenry and the future of the country. ‚ÄúI appeal to Mr. President to take the bull by the horn. He should act to stem the tide of this violence threatening to tear the country apart,‚Äù he added. Following in the footsteps of Saraki, his former deputy at the Senate, Ike Ekweremadu, also on Tuesday, called on the Federal Government to seek foreign help to fight insecurity in the country. Ekweremadu made the call while contributing to a motion moved during plenary by Senator Sani Musa on the activities of bandits and Boko Haram terrorists in Shiroro and Rafi Local Government Areas of Niger State. According to Senator Ekweremadu, any government that fails to protect its citizens has lost its legitimacy, therefore, the Federal Government should not be ashamed to seek foreign support, while also calling for a shutdown of Niger to enable security agencies to deal with the problem. On his part, a former Vice President, Alhaji Atiku Abubakar warned that there is looming darkness over the country, if the attacks on schools and abduction of students continue. Calling for a 24-hour arms guard in schools, Atiku opined that if the current situation persists, school enrollment will further decline. He said in a statement: ‚ÄúThe abduction of yet an unspecific number of undergraduates of the Federal University of Agriculture, Makurdi, Benue State, is one abduction too many. It marks both an unacceptable escalation and an expansion of this menace, and we must not only ensure that the abducted youths are rescued, but even more importantly, we must put in measures to prevent future reoccurrences. ‚ÄúThis must not be allowed to become our new normal. It is time for us as a nation to face the reality that we have an emergency on our hands. A catastrophe that must be decisively dealt with before it snowballs into an existential crisis. ‚ÄúWe must stop treating these acts of criminality with kid gloves. Enough is enough! There must be safety of lives and property in our citadels of learning, because without it, there would be loss of confidence in the sector, which will result in low enrolment rates in a country that is amongst the highest statistically for out-of-school children. ‚ÄúI renew the call I made on Monday, March 15, 2021, for a state of emergency to be declared on the education sector, and for 24 hour armed guards to be posted at all schools in the affected states. ‚ÄúYes, it is an expensive venture. Nevertheless, we must accept that whatever we invest in preserving the lives of Nigerian youths is worth the price, as nothing is, or can be more valuable to us than our youths, who will take up the baton after we are gone.‚Äù To put the icing on the cake, the usually blunt Governor of Benue State, Samuel Ortom, on Tuesday accused President Muhammadu Buhari of working for Fulanis to take over Nigeria. The Governor said: ‚ÄúWhat is happening now, to me, is very clear; Mr President is just working for these Fulanis to take over the whole country. ‚ÄúHis body language is what is being played out. The body language, the action and inaction of Mr President shows that he is only the President of Fulani people; I have known this. ‚ÄúWe are becoming a Banana Republic. If we have a President who gave the security agencies order to shoot at sight whosoever is having AK-47 and the Minister of Defence came out to say that they cannot shoot at sight. So who is the Commander-in-Chief of the Armed Forces?‚Äù According to Ortom, the people of Benue are being overstretched and running out of patience due to the incessant attacks on their communities. ‚ÄúMr President must rise up. He is the President of the Federal Republic of Nigeria and over the 250 nationalities that are in this country; Mr President is their President, we all voted him. ‚ÄúHe has taken oath of office to secure the country and provide security for lives and property; this is unacceptable, this cannot continue,‚Äù he said.\n"]}]},{"cell_type":"code","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["    public_id                                               text  \\\n","0    ff204eb9  Urgent action needed to save ‚Äòdying‚Äô high stre...   \n","1    97b3e15c  Denying 2000 years of the Medieval Warm Period...   \n","2         NaN  Dr. V.A. Shiva Ayyadurai, M.I.T. PhD, the Inve...   \n","3    18d2b528   Special Operations SOF units including 4,000 ...   \n","4    31d75b45  Bernie Sanders, an independent, represents Ver...   \n","..        ...                                                ...   \n","835  f2a01c39  Rises in National Insurance Contributions NICS...   \n","836  0399ea89  U.S. Government Finally Admits Marijuana Reall...   \n","837  9f89b2ba  The nosediving security situation in the count...   \n","838  866fa600  Coronavirus may be sexually transmitted and ca...   \n","839       NaN  A new study by the U.S. CDC raises the suspici...   \n","\n","                                                 title our rating  \\\n","0    Urgent action needed to save ‚Äòdying‚Äô high stre...      false   \n","1    Gov‚Äôt Seeks to Control ‚ÄòDisorderly‚Äô Internet P...      false   \n","2    Dr. Shiva at AZ Senate Hearing: Over 17,000 To...      false   \n","3    BREAKING: US Military at the White House Arres...      false   \n","4    Neil Mackay's Big Read: Inside Scotland‚Äôs educ...      false   \n","..                                                 ...        ...   \n","835  Budget 2017: National Insurance rate rise crit...      other   \n","836  Abe Lincoln Statue Vandalized With Poop, Paint...      other   \n","837  No help to buy ‚Äì the flagship government polic...      other   \n","838  Universal Credit leaves working families worse...      other   \n","839   Study proves: Wearing masks does not help at all      other   \n","\n","                                          ID  Unnamed: 0  \\\n","0                                        NaN         NaN   \n","1                                        NaN         NaN   \n","2    104589037423075649302005675867157134816         NaN   \n","3                                        NaN         NaN   \n","4                                        NaN         NaN   \n","..                                       ...         ...   \n","835                                      NaN         NaN   \n","836                                      NaN         NaN   \n","837                                      NaN         NaN   \n","838                                      NaN         NaN   \n","839  324897458105085510604238205575479586305       556.0   \n","\n","                                              keywords  \n","0    year, work, state, people, bill, report, time,...  \n","1    use, year, chick pizza, party work, also, incl...  \n","2    vaccine, people, study, also, report, covid, c...  \n","3    people, time, know, report, year, also, state,...  \n","4    year, also, report, time, country, government,...  \n","..                                                 ...  \n","835  self employ, national insurance, sst, also, da...  \n","836  vaccine, people, study, also, report, covid, c...  \n","837  country, people, vaccine, time, child, report,...  \n","838  year, also, report, time, country, government,...  \n","839  state, need, year, report, work, study, show, ...  \n","\n","[840 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-d91524f0-fc67-4651-a47e-9eac6842b0d6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>public_id</th>\n","      <th>text</th>\n","      <th>title</th>\n","      <th>our rating</th>\n","      <th>ID</th>\n","      <th>Unnamed: 0</th>\n","      <th>keywords</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ff204eb9</td>\n","      <td>Urgent action needed to save ‚Äòdying‚Äô high stre...</td>\n","      <td>Urgent action needed to save ‚Äòdying‚Äô high stre...</td>\n","      <td>false</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>year, work, state, people, bill, report, time,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>97b3e15c</td>\n","      <td>Denying 2000 years of the Medieval Warm Period...</td>\n","      <td>Gov‚Äôt Seeks to Control ‚ÄòDisorderly‚Äô Internet P...</td>\n","      <td>false</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>use, year, chick pizza, party work, also, incl...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>Dr. V.A. Shiva Ayyadurai, M.I.T. PhD, the Inve...</td>\n","      <td>Dr. Shiva at AZ Senate Hearing: Over 17,000 To...</td>\n","      <td>false</td>\n","      <td>104589037423075649302005675867157134816</td>\n","      <td>NaN</td>\n","      <td>vaccine, people, study, also, report, covid, c...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>18d2b528</td>\n","      <td>Special Operations SOF units including 4,000 ...</td>\n","      <td>BREAKING: US Military at the White House Arres...</td>\n","      <td>false</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>people, time, know, report, year, also, state,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>31d75b45</td>\n","      <td>Bernie Sanders, an independent, represents Ver...</td>\n","      <td>Neil Mackay's Big Read: Inside Scotland‚Äôs educ...</td>\n","      <td>false</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>year, also, report, time, country, government,...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>835</th>\n","      <td>f2a01c39</td>\n","      <td>Rises in National Insurance Contributions NICS...</td>\n","      <td>Budget 2017: National Insurance rate rise crit...</td>\n","      <td>other</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>self employ, national insurance, sst, also, da...</td>\n","    </tr>\n","    <tr>\n","      <th>836</th>\n","      <td>0399ea89</td>\n","      <td>U.S. Government Finally Admits Marijuana Reall...</td>\n","      <td>Abe Lincoln Statue Vandalized With Poop, Paint...</td>\n","      <td>other</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>vaccine, people, study, also, report, covid, c...</td>\n","    </tr>\n","    <tr>\n","      <th>837</th>\n","      <td>9f89b2ba</td>\n","      <td>The nosediving security situation in the count...</td>\n","      <td>No help to buy ‚Äì the flagship government polic...</td>\n","      <td>other</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>country, people, vaccine, time, child, report,...</td>\n","    </tr>\n","    <tr>\n","      <th>838</th>\n","      <td>866fa600</td>\n","      <td>Coronavirus may be sexually transmitted and ca...</td>\n","      <td>Universal Credit leaves working families worse...</td>\n","      <td>other</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>year, also, report, time, country, government,...</td>\n","    </tr>\n","    <tr>\n","      <th>839</th>\n","      <td>NaN</td>\n","      <td>A new study by the U.S. CDC raises the suspici...</td>\n","      <td>Study proves: Wearing masks does not help at all</td>\n","      <td>other</td>\n","      <td>324897458105085510604238205575479586305</td>\n","      <td>556.0</td>\n","      <td>state, need, year, report, work, study, show, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>840 rows √ó 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d91524f0-fc67-4651-a47e-9eac6842b0d6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d91524f0-fc67-4651-a47e-9eac6842b0d6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d91524f0-fc67-4651-a47e-9eac6842b0d6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["\n","df_all=data_brute\n","# modification du dataframe pour int√©grer les mots associ√©s au topic dominant √† chaque document\n","df_all['keywords']=df_topic_sents_keywords['topic_keywords']\n","display(df_all)\n","\n","df_all.to_csv('./Data_equilibre/mydata_topic.csv', sep=',', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":658},"id":"ul_wykkv_McX","executionInfo":{"status":"ok","timestamp":1682270860894,"user_tz":-120,"elapsed":191,"user":{"displayName":"Mathieu Cazeres","userId":"17539410092181857323"}},"outputId":"f45d28ed-7c98-437b-a0ba-35a92bc677e8"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[],"machine_shape":"hm"},"accelerator":"TPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}